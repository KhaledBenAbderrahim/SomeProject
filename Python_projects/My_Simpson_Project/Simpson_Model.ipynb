{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200, 3) 9877\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import imageio\n",
    "from tqdm.notebook import tqdm # forschritt balken\n",
    "#os.listdir('C:/Users/Akademie/Desktop/data_externe/data_simpson_extern')\n",
    "#Image.open('C:/Users/Akademie/Desktop/data_externe/data_simpson_extern/1.png')\n",
    "im = imageio.imread('C:/Users/Akademie/Desktop/data_externe/data_simpson_extern/1.png')\n",
    "files = os.listdir('C:/Users/Akademie/Desktop/data_externe/data_simpson_extern')\n",
    "print(im.shape,len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f03ee3cfb094d428642e012df719932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def read_images(path):\n",
    "    files = os.listdir(path)\n",
    "    files = [file for file in files if file[-4:] == \".png\"]\n",
    "    images = []\n",
    "    for file in tqdm(files):\n",
    "        try:\n",
    "            image = Image.open(os.path.join(path,file))\n",
    "\n",
    "            #https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=resize\n",
    "            image = image.resize((32,32),Image.LANCZOS)\n",
    "\n",
    "            #https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=resize\n",
    "            image = image.convert('RGB')\n",
    "            image = np.asarray(image)\n",
    "\n",
    "            images.append(image)\n",
    "        except OSError:\n",
    "            pass\n",
    "    return images\n",
    "\n",
    "simpsons = read_images('C:/Users/Akademie/Desktop/data_externe/data_simpson_extern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img scr ='C:/Users/Akademie/Desktop/data_externe/data_sympson_extern/1.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9877, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpsons = np.asarray(simpsons)\n",
    "simpsons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(simpsons[11])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19877, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Not_simpsons = X_test\n",
    "X = np.concatenate([simpsons,Not_simpsons])\n",
    "Xpp = X # für VGG16 später\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19877, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.concatenate([np.ones(len(simpsons)),np.zeros(len(Not_simpsons))])\n",
    "Y = Y.reshape(-1,1)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "311/311 [==============================] - 36s 115ms/step - loss: 0.2551 - acc: 0.8928\n",
      "Epoch 2/20\n",
      "311/311 [==============================] - 35s 114ms/step - loss: 0.0341 - acc: 0.9892\n",
      "Epoch 3/20\n",
      "311/311 [==============================] - 36s 117ms/step - loss: 0.0302 - acc: 0.99110s - loss: 0.0302 - acc: 0.991\n",
      "Epoch 4/20\n",
      "311/311 [==============================] - 39s 125ms/step - loss: 0.0219 - acc: 0.9927\n",
      "Epoch 5/20\n",
      "311/311 [==============================] - 41s 131ms/step - loss: 0.0184 - acc: 0.9944\n",
      "Epoch 6/20\n",
      "311/311 [==============================] - 38s 122ms/step - loss: 0.0146 - acc: 0.9952\n",
      "Epoch 7/20\n",
      "311/311 [==============================] - 38s 124ms/step - loss: 0.0189 - acc: 0.9947\n",
      "Epoch 8/20\n",
      "311/311 [==============================] - 37s 119ms/step - loss: 0.0108 - acc: 0.9963\n",
      "Epoch 9/20\n",
      "311/311 [==============================] - 38s 122ms/step - loss: 0.0111 - acc: 0.9963\n",
      "Epoch 10/20\n",
      "311/311 [==============================] - 40s 130ms/step - loss: 0.0069 - acc: 0.9982\n",
      "Epoch 11/20\n",
      "311/311 [==============================] - 39s 125ms/step - loss: 0.0075 - acc: 0.9973\n",
      "Epoch 12/20\n",
      "311/311 [==============================] - 39s 127ms/step - loss: 0.0064 - acc: 0.9981\n",
      "Epoch 13/20\n",
      "311/311 [==============================] - 38s 123ms/step - loss: 0.0064 - acc: 0.9978\n",
      "Epoch 14/20\n",
      "311/311 [==============================] - 39s 125ms/step - loss: 0.0074 - acc: 0.9976\n",
      "Epoch 15/20\n",
      "311/311 [==============================] - 37s 118ms/step - loss: 0.0065 - acc: 0.9975\n",
      "Epoch 16/20\n",
      "311/311 [==============================] - 36s 116ms/step - loss: 0.0078 - acc: 0.9976\n",
      "Epoch 17/20\n",
      "311/311 [==============================] - 37s 120ms/step - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 18/20\n",
      "311/311 [==============================] - 38s 122ms/step - loss: 0.0089 - acc: 0.9971\n",
      "Epoch 19/20\n",
      "311/311 [==============================] - 37s 120ms/step - loss: 0.0024 - acc: 0.9990\n",
      "Epoch 20/20\n",
      "311/311 [==============================] - 37s 118ms/step - loss: 0.0025 - acc: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x225788276c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Eigine Neureunale Netzt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense , MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(32,32,3)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001),loss='binary_crossentropy',metrics=['acc'])\n",
    "\n",
    "model.fit(X,Y,epochs = 20,batch_size = 64) # Sehr langsame Berechnung (ca. 20 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Simpson_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1639424   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,836,321\n",
      "Trainable params: 1,836,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model mit VVG16 Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input # preprocess_input fonktion teilt automatisch unter 255!!!!!\n",
    "\n",
    "X = preprocess_input(Xpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 100s 161ms/step\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = VGG16(include_top=False,input_shape=(32,32,3))\n",
    "vgg16_model.trainable = False\n",
    "#vgg16_model.summary()\n",
    "X_after_vgg = vgg16_model.predict(X , verbose=1) # verbose --> meine forschritt Balken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19877, 1, 1, 512)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_after_vgg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 526,337\n",
      "Trainable params: 526,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten\n",
    "\n",
    "model_vgg = Sequential()\n",
    "#model_vgg.add(vgg16_model)\n",
    "\n",
    "model_vgg.add(Flatten(input_shape=(1,1,512)))\n",
    "model_vgg.add(Dense(1024,activation='relu'))\n",
    "model_vgg.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model_vgg.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['acc'])\n",
    "\n",
    "model_vgg.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_after_vgg,Y = shuffle(X_after_vgg,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.3102 - acc: 0.9778 - val_loss: 0.1082 - val_acc: 0.9938\n",
      "Epoch 2/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0388 - acc: 0.9967 - val_loss: 0.0775 - val_acc: 0.9954\n",
      "Epoch 3/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0260 - acc: 0.9978 - val_loss: 0.0685 - val_acc: 0.9952\n",
      "Epoch 4/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0113 - acc: 0.9985 - val_loss: 0.0696 - val_acc: 0.9954\n",
      "Epoch 5/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0881 - val_acc: 0.9948\n",
      "Epoch 6/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0078 - acc: 0.9989 - val_loss: 0.1033 - val_acc: 0.9950\n",
      "Epoch 7/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0149 - acc: 0.9984 - val_loss: 0.1181 - val_acc: 0.9932\n",
      "Epoch 8/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0086 - acc: 0.9988 - val_loss: 0.1623 - val_acc: 0.9928\n",
      "Epoch 9/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0257 - acc: 0.9980 - val_loss: 0.1161 - val_acc: 0.9948\n",
      "Epoch 10/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0138 - acc: 0.9985 - val_loss: 0.1077 - val_acc: 0.9960\n",
      "Epoch 11/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0099 - acc: 0.9991 - val_loss: 0.1074 - val_acc: 0.9960\n",
      "Epoch 12/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0980 - val_acc: 0.9958\n",
      "Epoch 13/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0046 - acc: 0.9996 - val_loss: 0.1213 - val_acc: 0.9958\n",
      "Epoch 14/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0088 - acc: 0.9991 - val_loss: 0.2928 - val_acc: 0.9899\n",
      "Epoch 15/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0152 - acc: 0.9990 - val_loss: 0.2127 - val_acc: 0.9952\n",
      "Epoch 16/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0346 - acc: 0.9981 - val_loss: 0.1993 - val_acc: 0.9942\n",
      "Epoch 17/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0374 - acc: 0.9977 - val_loss: 0.1619 - val_acc: 0.9958\n",
      "Epoch 18/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0286 - acc: 0.9995 - val_loss: 0.1637 - val_acc: 0.9960\n",
      "Epoch 19/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.2111 - val_acc: 0.9956\n",
      "Epoch 20/20\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0052 - acc: 0.9996 - val_loss: 0.2377 - val_acc: 0.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x225838bf4c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg.fit(X_after_vgg,Y,epochs=20,batch_size=32,validation_split=0.25) \n",
    "# ca  2 min berechnung und bessere geneugkeit\n",
    "# validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.save('model_vgg_simpson.h5')\n",
    "#model.save('model_simpson.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
